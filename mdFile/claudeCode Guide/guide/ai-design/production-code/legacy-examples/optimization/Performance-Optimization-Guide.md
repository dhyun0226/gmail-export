# ì™„ì „í•œ ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ
> AIê°€ í™”ë©´ ì´ë¯¸ì§€ë¡œë¶€í„° ê³ ì„±ëŠ¥ ì• í”Œë¦¬ì¼€ì´ì…˜ ìµœì í™” ì‹œìŠ¤í…œì„ ìë™ ìƒì„±í•˜ëŠ” ê°€ì´ë“œ

## ğŸ¯ ëª©í‘œ
AIê°€ í™”ë©´ ì´ë¯¸ì§€ ë¶„ì„ í›„ **ì™„ì „í•œ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ**ì„ ìë™ ìƒì„±í•˜ì—¬ **ê³ ì„±ëŠ¥ ì• í”Œë¦¬ì¼€ì´ì…˜** êµ¬í˜„

## âš¡ ì™„ì „í•œ ì„±ëŠ¥ ìµœì í™” ì•„í‚¤í…ì²˜

### 1. Frontend ì„±ëŠ¥ ìµœì í™” (Vue 3)

#### 1.1 Bundle Optimization

##### vite.config.ts (ìµœì í™”ëœ ì„¤ì •)
```typescript
import { defineConfig } from 'vite';
import vue from '@vitejs/plugin-vue';
import { resolve } from 'path';
import { visualizer } from 'rollup-plugin-visualizer';
import { compression } from 'vite-plugin-compression';
import { VitePWA } from 'vite-plugin-pwa';
import legacy from '@vitejs/plugin-legacy';

export default defineConfig({
  plugins: [
    vue({
      script: {
        defineModel: true,
        propsDestructure: true
      },
      template: {
        compilerOptions: {
          // í”„ë¡œë•ì…˜ì—ì„œ ì£¼ì„ ì œê±°
          comments: false
        }
      }
    }),
    
    // ë ˆê±°ì‹œ ë¸Œë¼ìš°ì € ì§€ì›
    legacy({
      targets: ['defaults', 'not IE 11']
    }),
    
    // Gzip/Brotli ì••ì¶•
    compression({
      algorithm: 'gzip',
      threshold: 1024,
      deleteOriginFile: false
    }),
    compression({
      algorithm: 'brotliCompress',
      ext: '.br',
      threshold: 1024,
      deleteOriginFile: false
    }),
    
    // PWA ì„¤ì •
    VitePWA({
      registerType: 'autoUpdate',
      workbox: {
        globPatterns: ['**/*.{js,css,html,ico,png,svg,woff2}'],
        runtimeCaching: [
          {
            urlPattern: /^https:\/\/api\./,
            handler: 'NetworkFirst',
            options: {
              cacheName: 'api-cache',
              expiration: {
                maxEntries: 50,
                maxAgeSeconds: 60 * 60 * 24 // 24ì‹œê°„
              }
            }
          }
        ]
      }
    }),
    
    // ë²ˆë“¤ ë¶„ì„ê¸°
    visualizer({
      filename: 'dist/stats.html',
      open: true,
      gzipSize: true,
      brotliSize: true
    })
  ],
  
  resolve: {
    alias: {
      '@': resolve(__dirname, 'src'),
      '@ows/ui': resolve(__dirname, '../packages/main/src')
    }
  },
  
  build: {
    // ë²ˆë“¤ í¬ê¸° ì œí•œ
    chunkSizeWarningLimit: 1000,
    
    rollupOptions: {
      output: {
        // ì²­í¬ ë¶„í•  ì „ëµ
        manualChunks: {
          // ë²¤ë” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
          'vendor-vue': ['vue', 'vue-router', 'pinia'],
          'vendor-ui': ['@ows/ui', 'bootstrap-vue-next'],
          'vendor-devextreme': ['devextreme', 'devextreme-vue'],
          'vendor-utils': ['axios', 'dayjs', 'lodash-es'],
          
          // í° ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ ë³„ë„ ë¶„ë¦¬
          'vendor-charts': ['chart.js', 'vue-chartjs'],
          'vendor-icons': ['@fortawesome/fontawesome-free']
        },
        
        // íŒŒì¼ëª… ìµœì í™”
        chunkFileNames: (chunkInfo) => {
          const facadeModuleId = chunkInfo.facadeModuleId
            ? chunkInfo.facadeModuleId.split('/').pop().replace('.vue', '')
            : 'chunk';
          return `js/[name]-[hash].js`;
        },
        
        entryFileNames: 'js/[name]-[hash].js',
        assetFileNames: (assetInfo) => {
          const info = assetInfo.name.split('.');
          const ext = info[info.length - 1];
          
          if (/\.(png|jpe?g|gif|svg|webp|ico)$/.test(assetInfo.name)) {
            return `images/[name]-[hash][extname]`;
          }
          if (/\.(woff2?|eot|ttf|otf)$/.test(assetInfo.name)) {
            return `fonts/[name]-[hash][extname]`;
          }
          if (ext === 'css') {
            return `css/[name]-[hash][extname]`;
          }
          return `assets/[name]-[hash][extname]`;
        }
      }
    },
    
    // ì†ŒìŠ¤ë§µ ì„¤ì •
    sourcemap: process.env.NODE_ENV === 'development',
    
    // ìµœì†Œí™” ì„¤ì •
    minify: 'terser',
    terserOptions: {
      compress: {
        drop_console: process.env.NODE_ENV === 'production',
        drop_debugger: true,
        pure_funcs: ['console.log', 'console.info']
      },
      mangle: {
        safari10: true
      }
    },
    
    // CSS ìµœì í™”
    cssCodeSplit: true,
    cssMinify: true
  },
  
  // ê°œë°œ ì„œë²„ ìµœì í™”
  server: {
    port: 5173,
    host: true,
    hmr: {
      overlay: false
    }
  },
  
  // ë¯¸ë¦¬ ë²ˆë“¤ë§ ìµœì í™”
  optimizeDeps: {
    include: [
      'vue',
      'vue-router',
      'pinia',
      '@ows/ui',
      'axios',
      'dayjs'
    ],
    exclude: [
      'devextreme' // í° ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì œì™¸
    ]
  }
});
```

#### 1.2 Component Optimization

##### LazyLoadingMixin.ts
```typescript
import { defineComponent, ref, onMounted, onUnmounted } from 'vue';

export interface LazyLoadOptions {
  threshold?: number;
  rootMargin?: string;
  triggerOnce?: boolean;
}

export function useLazyLoading(options: LazyLoadOptions = {}) {
  const isVisible = ref(false);
  const targetRef = ref<HTMLElement>();
  
  let observer: IntersectionObserver | null = null;

  const {
    threshold = 0.1,
    rootMargin = '50px',
    triggerOnce = true
  } = options;

  onMounted(() => {
    if (!targetRef.value) return;

    observer = new IntersectionObserver(
      (entries) => {
        const entry = entries[0];
        if (entry.isIntersecting) {
          isVisible.value = true;
          
          if (triggerOnce && observer) {
            observer.disconnect();
          }
        } else if (!triggerOnce) {
          isVisible.value = false;
        }
      },
      {
        threshold,
        rootMargin
      }
    );

    observer.observe(targetRef.value);
  });

  onUnmounted(() => {
    if (observer) {
      observer.disconnect();
    }
  });

  return {
    isVisible,
    targetRef
  };
}

// ì´ë¯¸ì§€ ì§€ì—° ë¡œë”© ì»´í¬ë„ŒíŠ¸
export const LazyImage = defineComponent({
  name: 'LazyImage',
  props: {
    src: {
      type: String,
      required: true
    },
    alt: {
      type: String,
      default: ''
    },
    placeholder: {
      type: String,
      default: 'data:image/svg+xml,%3Csvg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 400 300"%3E%3Crect width="400" height="300" fill="%23f0f0f0"/%3E%3C/svg%3E'
    },
    loadingClass: {
      type: String,
      default: 'lazy-loading'
    },
    errorClass: {
      type: String,
      default: 'lazy-error'
    }
  },
  setup(props) {
    const { isVisible, targetRef } = useLazyLoading();
    const isLoaded = ref(false);
    const hasError = ref(false);
    const currentSrc = ref(props.placeholder);

    const loadImage = () => {
      const img = new Image();
      
      img.onload = () => {
        currentSrc.value = props.src;
        isLoaded.value = true;
      };
      
      img.onerror = () => {
        hasError.value = true;
      };
      
      img.src = props.src;
    };

    watch(isVisible, (visible) => {
      if (visible && !isLoaded.value && !hasError.value) {
        loadImage();
      }
    });

    return {
      targetRef,
      currentSrc,
      isLoaded,
      hasError,
      isVisible
    };
  },
  template: `
    <img
      ref="targetRef"
      :src="currentSrc"
      :alt="alt"
      :class="{
        [loadingClass]: isVisible && !isLoaded && !hasError,
        [errorClass]: hasError
      }"
      @load="isLoaded = true"
    />
  `
});
```

##### VirtualScrolling.vue
```vue
<template>
  <div 
    ref="containerRef"
    class="virtual-scroll-container"
    :style="{ height: `${containerHeight}px` }"
    @scroll="handleScroll"
  >
    <div 
      class="virtual-scroll-spacer"
      :style="{ 
        height: `${totalHeight}px`,
        paddingTop: `${offsetY}px`
      }"
    >
      <div
        v-for="item in visibleItems"
        :key="getItemKey(item)"
        class="virtual-scroll-item"
        :style="{ height: `${itemHeight}px` }"
      >
        <slot :item="item" :index="item.index" />
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onMounted, onUnmounted, watch } from 'vue';

interface Props {
  items: any[];
  itemHeight: number;
  containerHeight: number;
  buffer?: number;
  keyField?: string;
}

const props = withDefaults(defineProps<Props>(), {
  buffer: 5,
  keyField: 'id'
});

const containerRef = ref<HTMLElement>();
const scrollTop = ref(0);

// ê³„ì‚°ëœ ê°’ë“¤
const totalHeight = computed(() => props.items.length * props.itemHeight);

const visibleStartIndex = computed(() => {
  return Math.max(0, Math.floor(scrollTop.value / props.itemHeight) - props.buffer);
});

const visibleEndIndex = computed(() => {
  const endIndex = Math.min(
    props.items.length - 1,
    Math.ceil((scrollTop.value + props.containerHeight) / props.itemHeight) + props.buffer
  );
  return Math.max(visibleStartIndex.value, endIndex);
});

const visibleItems = computed(() => {
  return props.items.slice(visibleStartIndex.value, visibleEndIndex.value + 1)
    .map((item, index) => ({
      ...item,
      index: visibleStartIndex.value + index
    }));
});

const offsetY = computed(() => visibleStartIndex.value * props.itemHeight);

// ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
const handleScroll = (event: Event) => {
  const target = event.target as HTMLElement;
  scrollTop.value = target.scrollTop;
};

// ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë””ë°”ìš´ì‹±
const debouncedScroll = debounce(handleScroll, 16); // 60fps

// ì•„ì´í…œ í‚¤ ìƒì„±
const getItemKey = (item: any) => {
  return item[props.keyField] || item.index;
};

// íŠ¹ì • ì¸ë±ìŠ¤ë¡œ ìŠ¤í¬ë¡¤
const scrollToIndex = (index: number) => {
  if (containerRef.value) {
    const scrollPosition = index * props.itemHeight;
    containerRef.value.scrollTop = scrollPosition;
  }
};

// íŠ¹ì • ì•„ì´í…œìœ¼ë¡œ ìŠ¤í¬ë¡¤
const scrollToItem = (itemKey: any) => {
  const index = props.items.findIndex(item => getItemKey(item) === itemKey);
  if (index !== -1) {
    scrollToIndex(index);
  }
};

defineExpose({
  scrollToIndex,
  scrollToItem
});
</script>

<style scoped>
.virtual-scroll-container {
  overflow-y: auto;
  overflow-x: hidden;
}

.virtual-scroll-spacer {
  position: relative;
}

.virtual-scroll-item {
  overflow: hidden;
}
</style>
```

#### 1.3 State Management Optimization

##### optimizedStore.ts
```typescript
import { defineStore } from 'pinia';
import { ref, computed, shallowRef } from 'vue';
import { debounce } from 'lodash-es';

// ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ìƒíƒœ ê´€ë¦¬
export const useOptimizedStore = defineStore('optimized', () => {
  // í° ë°ì´í„°ëŠ” shallowRef ì‚¬ìš©
  const largeDataSet = shallowRef<any[]>([]);
  const cacheMap = new Map<string, any>();
  const loadingStates = ref<Record<string, boolean>>({});
  
  // ë©”ëª¨ì´ì œì´ì…˜ëœ ê³„ì‚°
  const memoizedComputed = computed(() => {
    const cacheKey = JSON.stringify(largeDataSet.value.map(item => item.id));
    
    if (cacheMap.has(cacheKey)) {
      return cacheMap.get(cacheKey);
    }
    
    const result = expensiveComputation(largeDataSet.value);
    cacheMap.set(cacheKey, result);
    
    // ìºì‹œ í¬ê¸° ì œí•œ
    if (cacheMap.size > 100) {
      const firstKey = cacheMap.keys().next().value;
      cacheMap.delete(firstKey);
    }
    
    return result;
  });

  // ë””ë°”ìš´ì‹±ëœ ì•¡ì…˜
  const debouncedSave = debounce(async (data: any) => {
    setLoading('save', true);
    try {
      await api.save(data);
    } finally {
      setLoading('save', false);
    }
  }, 300);

  // ë°°ì¹˜ ì—…ë°ì´íŠ¸
  const batchUpdate = (updates: Array<{ id: string; changes: any }>) => {
    // ë³€ê²½ì‚¬í•­ë“¤ì„ ëª¨ì•„ì„œ í•œ ë²ˆì— ì²˜ë¦¬
    const updatedItems = largeDataSet.value.map(item => {
      const update = updates.find(u => u.id === item.id);
      return update ? { ...item, ...update.changes } : item;
    });
    
    largeDataSet.value = updatedItems;
  };

  // í˜ì´ì§€ë„¤ì´ì…˜ëœ ë°ì´í„° ë¡œë”©
  const loadPage = async (page: number, size: number = 20) => {
    const cacheKey = `page_${page}_${size}`;
    
    if (cacheMap.has(cacheKey)) {
      return cacheMap.get(cacheKey);
    }
    
    setLoading('loadPage', true);
    try {
      const data = await api.getPage(page, size);
      cacheMap.set(cacheKey, data);
      return data;
    } finally {
      setLoading('loadPage', false);
    }
  };

  // ë°±ê·¸ë¼ìš´ë“œ í”„ë¦¬í˜ì¹­
  const prefetchNext = async (currentPage: number, size: number = 20) => {
    const nextPage = currentPage + 1;
    const cacheKey = `page_${nextPage}_${size}`;
    
    if (!cacheMap.has(cacheKey)) {
      // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë‹¤ìŒ í˜ì´ì§€ ë¯¸ë¦¬ ë¡œë”©
      api.getPage(nextPage, size)
        .then(data => cacheMap.set(cacheKey, data))
        .catch(() => {}); // ì—ëŸ¬ ë¬´ì‹œ
    }
  };

  // ë©”ëª¨ë¦¬ ì •ë¦¬
  const cleanup = () => {
    cacheMap.clear();
    largeDataSet.value = [];
  };

  // ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
  const setLoading = (key: string, value: boolean) => {
    loadingStates.value[key] = value;
  };

  const isLoading = (key: string) => {
    return computed(() => loadingStates.value[key] || false);
  };

  const expensiveComputation = (data: any[]) => {
    // ë¬´ê±°ìš´ ê³„ì‚° ë¡œì§
    return data.reduce((acc, item) => {
      return acc + (item.value || 0);
    }, 0);
  };

  return {
    largeDataSet: readonly(largeDataSet),
    memoizedComputed,
    loadingStates: readonly(loadingStates),
    
    debouncedSave,
    batchUpdate,
    loadPage,
    prefetchNext,
    cleanup,
    isLoading
  };
});
```

### 2. Backend ì„±ëŠ¥ ìµœì í™” (Spring Boot)

#### 2.1 Database Optimization

##### DatabaseConfig.java
```java
package com.ows.demo.config;

import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;
import lombok.RequiredArgsConstructor;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.data.jpa.repository.config.EnableJpaRepositories;
import org.springframework.orm.jpa.JpaTransactionManager;
import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean;
import org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter;
import org.springframework.transaction.PlatformTransactionManager;
import org.springframework.transaction.annotation.EnableTransactionManagement;

import javax.sql.DataSource;
import java.util.Properties;

@Configuration
@EnableTransactionManagement
@EnableJpaRepositories(
    basePackages = "com.ows.demo.repository",
    entityManagerFactoryRef = "entityManagerFactory",
    transactionManagerRef = "transactionManager"
)
@RequiredArgsConstructor
public class DatabaseConfig {

    @Bean
    @Primary
    @ConfigurationProperties("spring.datasource.hikari")
    public HikariConfig hikariConfig() {
        HikariConfig config = new HikariConfig();
        
        // ì»¤ë„¥ì…˜ í’€ ìµœì í™”
        config.setMaximumPoolSize(20);
        config.setMinimumIdle(5);
        config.setConnectionTimeout(30000);
        config.setIdleTimeout(600000);
        config.setMaxLifetime(1800000);
        config.setLeakDetectionThreshold(60000);
        
        // ì„±ëŠ¥ ìµœì í™”
        config.setConnectionTestQuery("SELECT 1");
        config.setValidationTimeout(3000);
        config.setInitializationFailTimeout(1);
        
        // ì»¤ë„¥ì…˜ í’€ ëª¨ë‹ˆí„°ë§
        config.setRegisterMbeans(true);
        config.setPoolName("OWSHikariPool");
        
        return config;
    }

    @Bean
    @Primary
    public DataSource dataSource() {
        return new HikariDataSource(hikariConfig());
    }

    @Bean
    @Primary
    public LocalContainerEntityManagerFactoryBean entityManagerFactory() {
        LocalContainerEntityManagerFactoryBean em = new LocalContainerEntityManagerFactoryBean();
        em.setDataSource(dataSource());
        em.setPackagesToScan("com.ows.demo.entity");
        
        HibernateJpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter();
        vendorAdapter.setGenerateDdl(false);
        vendorAdapter.setShowSql(false);
        em.setJpaVendorAdapter(vendorAdapter);
        
        // Hibernate ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        Properties properties = new Properties();
        
        // ì¿¼ë¦¬ ìµœì í™”
        properties.setProperty("hibernate.dialect", "org.hibernate.dialect.PostgreSQLDialect");
        properties.setProperty("hibernate.hbm2ddl.auto", "validate");
        properties.setProperty("hibernate.show_sql", "false");
        properties.setProperty("hibernate.format_sql", "false");
        
        // ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
        properties.setProperty("hibernate.jdbc.batch_size", "25");
        properties.setProperty("hibernate.jdbc.batch_versioned_data", "true");
        properties.setProperty("hibernate.order_inserts", "true");
        properties.setProperty("hibernate.order_updates", "true");
        
        // ìºì‹œ ì„¤ì •
        properties.setProperty("hibernate.cache.use_second_level_cache", "true");
        properties.setProperty("hibernate.cache.use_query_cache", "true");
        properties.setProperty("hibernate.cache.region.factory_class", 
            "org.hibernate.cache.jcache.JCacheRegionFactory");
        
        // ì§€ì—° ë¡œë”© ìµœì í™”
        properties.setProperty("hibernate.enable_lazy_load_no_trans", "false");
        properties.setProperty("hibernate.jdbc.fetch_size", "50");
        
        // í†µê³„ ë° ëª¨ë‹ˆí„°ë§
        properties.setProperty("hibernate.generate_statistics", "true");
        properties.setProperty("hibernate.session.events.log.LOG_QUERIES_SLOWER_THAN_MS", "100");
        
        em.setJpaProperties(properties);
        return em;
    }

    @Bean
    @Primary
    public PlatformTransactionManager transactionManager() {
        JpaTransactionManager transactionManager = new JpaTransactionManager();
        transactionManager.setEntityManagerFactory(entityManagerFactory().getObject());
        return transactionManager;
    }
}
```

#### 2.2 Caching Strategy

##### CacheConfig.java
```java
package com.ows.demo.config;

import com.github.benmanes.caffeine.cache.Caffeine;
import lombok.extern.slf4j.Slf4j;
import org.springframework.cache.CacheManager;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.cache.caffeine.CaffeineCacheManager;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.data.redis.cache.RedisCacheConfiguration;
import org.springframework.data.redis.cache.RedisCacheManager;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;
import org.springframework.data.redis.serializer.RedisSerializationContext;
import org.springframework.data.redis.serializer.StringRedisSerializer;

import java.time.Duration;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.TimeUnit;

@Slf4j
@Configuration
@EnableCaching
public class CacheConfig {

    // L1 ìºì‹œ (ë¡œì»¬ - Caffeine)
    @Bean
    public CacheManager localCacheManager() {
        CaffeineCacheManager cacheManager = new CaffeineCacheManager();
        
        cacheManager.setCaffeine(Caffeine.newBuilder()
            .initialCapacity(100)
            .maximumSize(1000)
            .expireAfterWrite(10, TimeUnit.MINUTES)
            .expireAfterAccess(5, TimeUnit.MINUTES)
            .recordStats()
            .removalListener((key, value, cause) -> {
                log.debug("Local cache eviction: key={}, cause={}", key, cause);
            }));
            
        // ìºì‹œë³„ ì„¤ì •
        cacheManager.setCacheNames(
            "users", "products", "categories", "permissions", "settings"
        );
        
        return cacheManager;
    }

    // L2 ìºì‹œ (ë¶„ì‚° - Redis)
    @Bean
    @Primary
    public CacheManager distributedCacheManager(RedisConnectionFactory connectionFactory) {
        RedisCacheConfiguration defaultConfig = RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofMinutes(30))
            .serializeKeysWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new StringRedisSerializer()))
            .serializeValuesWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new GenericJackson2JsonRedisSerializer()))
            .disableCachingNullValues();

        // ìºì‹œë³„ ê°œë³„ ì„¤ì •
        Map<String, RedisCacheConfiguration> cacheConfigurations = new HashMap<>();
        
        // ì‚¬ìš©ì ì •ë³´ - ê¸´ TTL
        cacheConfigurations.put("users", defaultConfig
            .entryTtl(Duration.ofHours(1)));
            
        // ìƒí’ˆ ì •ë³´ - ì¤‘ê°„ TTL
        cacheConfigurations.put("products", defaultConfig
            .entryTtl(Duration.ofMinutes(30)));
            
        // ì¹´í…Œê³ ë¦¬ - ê¸´ TTL (ìì£¼ ë³€ê²½ë˜ì§€ ì•ŠìŒ)
        cacheConfigurations.put("categories", defaultConfig
            .entryTtl(Duration.ofHours(6)));
            
        // ê¶Œí•œ ì •ë³´ - ì¤‘ê°„ TTL
        cacheConfigurations.put("permissions", defaultConfig
            .entryTtl(Duration.ofMinutes(45)));
            
        // ì„¤ì • ì •ë³´ - ê¸´ TTL
        cacheConfigurations.put("settings", defaultConfig
            .entryTtl(Duration.ofHours(2)));
            
        // ì„¸ì…˜ ìºì‹œ - ì§§ì€ TTL
        cacheConfigurations.put("sessions", defaultConfig
            .entryTtl(Duration.ofMinutes(15)));

        return RedisCacheManager.builder(connectionFactory)
            .cacheDefaults(defaultConfig)
            .withInitialCacheConfigurations(cacheConfigurations)
            .transactionAware()
            .build();
    }
}
```

##### CacheService.java
```java
package com.ows.demo.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.cache.annotation.CacheEvict;
import org.springframework.cache.annotation.CachePut;
import org.springframework.cache.annotation.Cacheable;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.stereotype.Service;

import java.time.Duration;
import java.util.Collection;
import java.util.List;
import java.util.concurrent.CompletableFuture;

@Slf4j
@Service
@RequiredArgsConstructor
public class CacheService {

    private final RedisTemplate<String, Object> redisTemplate;

    // ë©€í‹°ë ˆë²¨ ìºì‹±
    @Cacheable(value = "products", key = "#id", cacheManager = "localCacheManager")
    public ProductDto getProductFromLocalCache(Long id) {
        return getProductFromDistributedCache(id);
    }

    @Cacheable(value = "products", key = "#id", cacheManager = "distributedCacheManager")
    public ProductDto getProductFromDistributedCache(Long id) {
        // ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
        return productRepository.findById(id)
            .map(productMapper::toDto)
            .orElse(null);
    }

    // ìºì‹œ ì›Œë°ì—…
    public void warmupCache() {
        log.info("Starting cache warmup...");
        
        CompletableFuture.runAsync(() -> {
            // ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„° ë¯¸ë¦¬ ë¡œë”©
            preloadPopularProducts();
            preloadCategories();
            preloadUserPermissions();
        });
    }

    private void preloadPopularProducts() {
        List<Long> popularProductIds = getPopularProductIds();
        
        popularProductIds.parallelStream()
            .forEach(this::getProductFromLocalCache);
            
        log.info("Preloaded {} popular products", popularProductIds.size());
    }

    private void preloadCategories() {
        List<CategoryDto> categories = categoryService.getAllCategories();
        
        categories.forEach(category -> {
            redisTemplate.opsForValue().set(
                "category:" + category.getId(),
                category,
                Duration.ofHours(6)
            );
        });
        
        log.info("Preloaded {} categories", categories.size());
    }

    // ìºì‹œ ë¬´íš¨í™” ì „ëµ
    @CacheEvict(value = "products", key = "#id", 
                cacheManager = "localCacheManager")
    public void evictProductFromLocalCache(Long id) {
        evictProductFromDistributedCache(id);
    }

    @CacheEvict(value = "products", key = "#id", 
                cacheManager = "distributedCacheManager")
    public void evictProductFromDistributedCache(Long id) {
        log.debug("Evicted product {} from all caches", id);
    }

    // íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”
    public void evictCacheByPattern(String pattern) {
        redisTemplate.execute((connection) -> {
            connection.eval(
                "local keys = redis.call('keys', ARGV[1]) " +
                "for i=1,#keys,5000 do " +
                "redis.call('del', unpack(keys, i, math.min(i+4999, #keys))) " +
                "end " +
                "return #keys".getBytes(),
                0,
                pattern.getBytes()
            );
            return null;
        });
    }

    // ìºì‹œ í†µê³„
    public CacheStatistics getCacheStatistics() {
        // Caffeine í†µê³„
        CacheManager localCacheManager = applicationContext.getBean(
            "localCacheManager", CacheManager.class);
            
        CacheStatistics.Builder builder = CacheStatistics.builder();
        
        localCacheManager.getCacheNames().forEach(cacheName -> {
            Cache cache = localCacheManager.getCache(cacheName);
            if (cache instanceof CaffeineCache) {
                com.github.benmanes.caffeine.cache.Cache<Object, Object> nativeCache = 
                    ((CaffeineCache) cache).getNativeCache();
                    
                CacheStatistics.CacheStats stats = CacheStatistics.CacheStats.builder()
                    .cacheName(cacheName)
                    .hitCount(nativeCache.stats().hitCount())
                    .missCount(nativeCache.stats().missCount())
                    .hitRate(nativeCache.stats().hitRate())
                    .evictionCount(nativeCache.stats().evictionCount())
                    .size(nativeCache.estimatedSize())
                    .build();
                    
                builder.addCacheStats(stats);
            }
        });
        
        return builder.build();
    }
}
```

#### 2.3 Query Optimization

##### OptimizedRepository.java
```java
package com.ows.demo.repository;

import com.ows.demo.entity.Product;
import org.springframework.data.domain.Page;
import org.springframework.data.domain.Pageable;
import org.springframework.data.jpa.repository.JpaRepository;
import org.springframework.data.jpa.repository.Query;
import org.springframework.data.jpa.repository.QueryHints;
import org.springframework.data.repository.query.Param;

import jakarta.persistence.QueryHint;
import java.util.List;
import java.util.Optional;

public interface OptimizedProductRepository extends JpaRepository<Product, Long> {

    // í˜ì¹˜ ì¡°ì¸ìœ¼ë¡œ N+1 ë¬¸ì œ í•´ê²°
    @Query("SELECT DISTINCT p FROM Product p " +
           "LEFT JOIN FETCH p.category " +
           "LEFT JOIN FETCH p.tags " +
           "WHERE p.status = 'ACTIVE'")
    @QueryHints({
        @QueryHint(name = "org.hibernate.cacheable", value = "true"),
        @QueryHint(name = "org.hibernate.cacheRegion", value = "products")
    })
    List<Product> findActiveProductsWithDetails();

    // ì½ê¸° ì „ìš© ì¿¼ë¦¬ ìµœì í™”
    @Query("SELECT p FROM Product p WHERE p.id = :id")
    @QueryHints({
        @QueryHint(name = "org.hibernate.readOnly", value = "true"),
        @QueryHint(name = "org.hibernate.cacheable", value = "true")
    })
    Optional<Product> findByIdReadOnly(@Param("id") Long id);

    // í”„ë¡œì ì…˜ì„ í†µí•œ í•„ìš”í•œ í•„ë“œë§Œ ì¡°íšŒ
    @Query("SELECT new com.ows.demo.dto.ProductSummaryDto(" +
           "p.id, p.name, p.price, p.status, c.name) " +
           "FROM Product p JOIN p.category c " +
           "WHERE p.status IN :statuses")
    Page<ProductSummaryDto> findProductSummaries(
        @Param("statuses") List<ProductStatus> statuses,
        Pageable pageable
    );

    // ë°°ì¹˜ í¬ê¸° íŒíŠ¸ë¡œ ì„±ëŠ¥ ìµœì í™”
    @Query("SELECT p FROM Product p WHERE p.id IN :ids")
    @QueryHints({
        @QueryHint(name = "org.hibernate.fetchSize", value = "50")
    })
    List<Product> findAllByIdsBatch(@Param("ids") List<Long> ids);

    // ë„¤ì´í‹°ë¸Œ ì¿¼ë¦¬ë¡œ ë³µì¡í•œ ì¡°íšŒ ìµœì í™”
    @Query(value = """
        WITH product_stats AS (
            SELECT 
                p.id,
                p.name,
                p.price,
                COUNT(o.id) as order_count,
                AVG(r.rating) as avg_rating
            FROM products p
            LEFT JOIN order_items oi ON p.id = oi.product_id
            LEFT JOIN orders o ON oi.order_id = o.id
            LEFT JOIN reviews r ON p.id = r.product_id
            WHERE p.status = 'ACTIVE'
              AND o.created_at >= :fromDate
            GROUP BY p.id, p.name, p.price
        )
        SELECT * FROM product_stats
        ORDER BY order_count DESC, avg_rating DESC
        LIMIT :limit
        """, nativeQuery = true)
    List<Object[]> findTopSellingProducts(
        @Param("fromDate") LocalDateTime fromDate,
        @Param("limit") int limit
    );

    // ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
    @Query("SELECT p FROM Product p WHERE p.status = :status")
    @QueryHints({
        @QueryHint(name = "org.hibernate.fetchSize", value = "100"),
        @QueryHint(name = "org.hibernate.readOnly", value = "true")
    })
    Stream<Product> streamByStatus(@Param("status") ProductStatus status);
}
```

#### 2.4 Async Processing

##### AsyncService.java
```java
package com.ows.demo.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Async;
import org.springframework.scheduling.annotation.AsyncResult;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.List;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.stream.IntStream;

@Slf4j
@Service
@RequiredArgsConstructor
public class AsyncProcessingService {

    private final ProductRepository productRepository;
    private final NotificationService notificationService;
    private final ExecutorService customExecutor = 
        Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());

    // ë¹„ë™ê¸° ì²˜ë¦¬
    @Async("taskExecutor")
    public CompletableFuture<Void> processLargeDatasetAsync(List<ProductDto> products) {
        log.info("Starting async processing of {} products", products.size());
        
        try {
            // ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            int chunkSize = 100;
            List<List<ProductDto>> chunks = partition(products, chunkSize);
            
            // ë³‘ë ¬ ì²˜ë¦¬
            CompletableFuture<?>[] futures = chunks.stream()
                .map(this::processChunkAsync)
                .toArray(CompletableFuture[]::new);
            
            CompletableFuture.allOf(futures).join();
            
            log.info("Completed async processing of {} products", products.size());
            return AsyncResult.forValue(null).completable();
            
        } catch (Exception e) {
            log.error("Error in async processing", e);
            return AsyncResult.forExecutionException(e).completable();
        }
    }

    private CompletableFuture<Void> processChunkAsync(List<ProductDto> chunk) {
        return CompletableFuture.runAsync(() -> {
            chunk.forEach(this::processProduct);
        }, customExecutor);
    }

    // ë°±ê·¸ë¼ìš´ë“œ ë°ì´í„° ë™ê¸°í™”
    @Async("scheduledTaskExecutor")
    @Transactional
    public CompletableFuture<Void> syncDataInBackground() {
        log.info("Starting background data sync");
        
        try {
            // ì™¸ë¶€ ì‹œìŠ¤í…œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            List<ExternalProductData> externalData = fetchExternalData();
            
            // ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—…ë°ì´íŠ¸
            updateProductsInBatch(externalData);
            
            // ìºì‹œ ë¬´íš¨í™”
            cacheService.evictCacheByPattern("products:*");
            
            log.info("Background data sync completed");
            return AsyncResult.forValue(null).completable();
            
        } catch (Exception e) {
            log.error("Background sync failed", e);
            return AsyncResult.forExecutionException(e).completable();
        }
    }

    // ì´ë©”ì¼ ë°œì†¡ ë¹„ë™ê¸° ì²˜ë¦¬
    @Async("notificationExecutor")
    public CompletableFuture<Void> sendBulkEmailsAsync(List<String> recipients, EmailTemplate template) {
        log.info("Starting bulk email sending to {} recipients", recipients.size());
        
        try {
            // ë°°ì¹˜ í¬ê¸° ì œí•œ (ì´ë©”ì¼ ì„œë¹„ìŠ¤ ì œì•½ ê³ ë ¤)
            int batchSize = 50;
            List<List<String>> batches = partition(recipients, batchSize);
            
            for (List<String> batch : batches) {
                sendEmailBatch(batch, template);
                
                // ì†ë„ ì œí•œ (Rate limiting)
                Thread.sleep(1000);
            }
            
            log.info("Bulk email sending completed");
            return AsyncResult.forValue(null).completable();
            
        } catch (Exception e) {
            log.error("Bulk email sending failed", e);
            return AsyncResult.forExecutionException(e).completable();
        }
    }

    // íŒŒì¼ ì²˜ë¦¬ ë¹„ë™ê¸°
    @Async("fileProcessingExecutor")
    public CompletableFuture<FileProcessingResult> processFileAsync(MultipartFile file) {
        log.info("Starting async file processing: {}", file.getOriginalFilename());
        
        try {
            // íŒŒì¼ ìœ íš¨ì„± ê²€ì¦
            validateFile(file);
            
            // íŒŒì¼ ì €ì¥
            String savedPath = fileStorageService.store(file);
            
            // íŒŒì¼ ë‚´ìš© ì²˜ë¦¬ (ì˜ˆ: Excel íŒŒì‹±)
            List<ProductDto> products = parseExcelFile(file);
            
            // ë°ì´í„° ê²€ì¦ ë° ì €ì¥
            List<ValidationError> errors = validateProducts(products);
            if (errors.isEmpty()) {
                saveProducts(products);
            }
            
            FileProcessingResult result = FileProcessingResult.builder()
                .filePath(savedPath)
                .processedCount(products.size())
                .errorCount(errors.size())
                .errors(errors)
                .build();
            
            log.info("File processing completed: {}", result);
            return AsyncResult.forValue(result).completable();
            
        } catch (Exception e) {
            log.error("File processing failed", e);
            return AsyncResult.forExecutionException(e).completable();
        }
    }

    // ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ
    private <T> List<List<T>> partition(List<T> list, int size) {
        return IntStream.range(0, (list.size() + size - 1) / size)
            .mapToObj(i -> list.subList(i * size, Math.min((i + 1) * size, list.size())))
            .collect(Collectors.toList());
    }
}
```

## ğŸ¯ ê²°ë¡ 

### âœ… **ì™„ì „í•œ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ**
1. **Frontend ìµœì í™”** - ë²ˆë“¤ ë¶„í• , ì§€ì—° ë¡œë”©, ê°€ìƒ ìŠ¤í¬ë¡¤ë§
2. **Backend ìµœì í™”** - ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”, ìºì‹± ì „ëµ
3. **ì¿¼ë¦¬ ìµœì í™”** - N+1 ë¬¸ì œ í•´ê²°, ì¸ë±ìŠ¤ í™œìš©
4. **ë¹„ë™ê¸° ì²˜ë¦¬** - ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…, ë³‘ë ¬ ì²˜ë¦¬
5. **ë©”ëª¨ë¦¬ ê´€ë¦¬** - íš¨ìœ¨ì ì¸ ìƒíƒœ ê´€ë¦¬, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜

### ğŸš€ **AIê°€ ì´ì œ ìƒì„± ê°€ëŠ¥í•œ ê²ƒ**
- **ê³ ì„±ëŠ¥ ì• í”Œë¦¬ì¼€ì´ì…˜ ì•„í‚¤í…ì²˜**
- **ìµœì í™”ëœ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„**
- **íš¨ìœ¨ì ì¸ ìºì‹± ì „ëµ**
- **í™•ì¥ ê°€ëŠ¥í•œ ë¹„ë™ê¸° ì‹œìŠ¤í…œ**

ì´ì œ AIê°€ **í™”ë©´ ì´ë¯¸ì§€ â†’ ì™„ì „í•œ ê³ ì„±ëŠ¥ ì‹œìŠ¤í…œ**ì„ ìë™ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ‰